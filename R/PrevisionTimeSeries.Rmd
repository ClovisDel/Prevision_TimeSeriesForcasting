---
title: 
  
author: 
- Clovis Deletre
- Charles Vitry
date:
output:
  word_document
#     bookdown::gitbook:
#       config:
# #        sharing:null
#         search: no
# documentclass: book
# bibliography: [book.bib, packages.bib]
# biblio-style: apalike
# link-citation: yes
# #github-repo:
# description: "Description"


always_allow_html: true
#     :
#     theme: cerulean
#     number_sections: no
#     toc: yes
#     toc_float: true
# editor_options: 
#   markdown: 
#     wrap: 72
---

```{=html}
<style type="text/css">

body{ /* Normal  */
      font-size: 20px;
  }
td {  /* Table  */
  font-size: 8px;
}
h1.title {
  font-size: 55px;
  color: DarkBlue;
}
h1 { /* Header 1 */
  font-size: 38px;
  color: DarkBlue;
}
h2 { /* Header 2 */
    font-size: 28px;
  color: DarkBlue;
}
h3 { /* Header 3 */
  font-size: 35px;
  font-family: "Times New Roman", Times, serif;
  color: DarkBlue;
}
code.r{ /* Code block */
    font-size: 12px;
}
pre { /* Code block - determines code spacing between lines */
    font-size: 14px;
}
</style>
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

source("Fonctions.R", local = knitr::knit_global())

#install for export in pdf file
#tinytex::install_tinytex()
```

<br> </br>

```{r include=FALSE}
if(!require(forecast)) install.packages("tm", repos = "http://cran.us.r-project.org")
require(forecast)

if(!require(fpp2)) install.packages("tm", repos = "http://cran.us.r-project.org")
require(fpp2)

if(!require(MLmetrics)) install.packages("tm", repos = "http://cran.us.r-project.org")
require(MLmetrics)

if(!require(ggplot2)) install.packages("tm", repos = "http://cran.us.r-project.org")
require(ggplot2)

if(!require(fpp2)) install.packages("tm", repos = "http://cran.us.r-project.org")
require(fpp2)

if(!require(TSstudio)) install.packages("tm", repos = "http://cran.us.r-project.org")
require(TSstudio)

if(!require(ggthemes)) install.packages("tm", repos = "http://cran.us.r-project.org")
require(ggthemes)

if(!require(timetk)) install.packages("tm", repos = "http://cran.us.r-project.org")
require(timetk)


```

```{r include=FALSE}
if(!require(keras)) install.packages("tm", repos = "http://cran.us.r-project.org")
require(keras)
if(!require(tensorflow)) install.packages("tm", repos = "http://cran.us.r-project.org")
require(tensorflow)
library(keras)
library(tensorflow)
#install_keras()
#install_tensorflow(version = "nightly")

#Set up Font
windowsFonts("Rubik" = windowsFont("Rubik"))
```

# Introduction

Nous souhaitons réalisé l'**étude d'une série temporelle** et faire des prévisions sur celle-ci.

Cette série temporelle est le trafic mensuel d'une Compagnie aérienne de janvier 2011 à août 2019.

Nos prévisions portent sur les 8 mois de l'année 2019

# Représentation graphique de la série.

## Import des données

Import de la base, on sélectionne la colonne des valeurs

```{r}
library(readr)
data <- read_delim("Trafic-voyageurs.csv", 
    delim = ";", locale = locale(encoding = "ISO-8859-1"))
```

```{r}
data_value <- data[,2]
summary(data)
```




## Création de notre série temporelle

Nous représentons nos données sous forme de série temporelle.

Une série temporelle est un ensemble de métrique mésurée sur des intervalles de temps réguliers.

Création de la série chronologique avec la librairie TSstudio :

-   start : année de début,
-   frequency : nbr de valeur par an =\> on en fréquence mensuelle donc 12

```{r}
library(TSstudio)
data_ts <- ts(data_value, start = 2011, frequency = 12)
plot_1_TimeSeries(data_ts)


```


## Séparation jeu de données

```{r}
#revoir l affichage car ca prend pas en compte tt 2019
data_ts_train <-
  window(data_ts, start = c(2011, 1), end = c(2018, 12))
data_ts_test <- window(data_ts, start = c(2019, 1), end = c(2019, 8))

names(data)[1] <- "ds"
names(data)[2] <- "y"
data_train <- data[1:96, ]
data_test <- data[97:104, ]


plot(data_ts, xlim = c(2011, 2020))
lines(data_ts_test, col = 3)
legend(
  "topleft",
  lty = 1,
  col = c(1, 3),
  legend = c("Série chronologique Train", "Série chronologique Test")
)
```

-\> strong trend -\> patern qui se repete, saisonnalité ?

## Représentation de la saisonnalité

Analyse de la saisonnalité en superposant chaque année (par mois):

-\> en supprimant la tendance on voit bien la saisonnalité =\> saisonnalité régulière

## Analyse de notre série temporelle

Chaque point de notre série temporelle peut être exprimer comme une somme ou un produit de 3 composantes : - Saisonnalité (St), - Tendance (Tt), - Erreur (ϵt),

Yt=St+Tt+ϵt ou Yt=St×Tt×ϵt

La stationnarité d'une série signifique que le processus qui génère la série ne change pas dans le temps. Cela ne veut pas dire que la série ne change pas dans le temps, mais que la façon dont elle change, n'est pas modifié dans le temps.

Testons si la série est stationnaire :

```{r}
library(tseries)
adf.test(data_ts) #p-value <0.5 => on ne rejete pas H0 => non stationnaire
kpss.test(data_ts)

```

Donc notre série est bien non-stationnaire.

```{r}
ggseasonplot(data_ts)

```

```{r}
data_ts_without_trend = diff(data_ts)
SeasonPlot <-  ggseasonplot(data_ts_without_trend) +
  labs(
    title = "Trafic sans la tendance",
    subtitle = "Visualisation de la saisonnalité",
    x = "Mois",
    y = "Nombre de Voyageurs"
  ) +
  geom_line(size = 1.1, alpha = 0.65) +
  theme_fivethirtyeight() +
  theme(axis.title = element_text()) +
  scale_color_brewer(palette = "Paired") +
  theme(axis.title = element_text(), text = element_text(family = "Rubik"))

SeasonPlot
```

## Représentation des décompositions possibles

DECOMPOSITION : additive / Multiplicative Ts = Trend + Seasonal + Random / Ts = Trend \* Seasonal \* Random

```{r}
decomposed_data <- decompose(data_ts_train, type="additive")
plot(decomposed_data$trend)
plot(decomposed_data$seasonal)
plot(decomposed_data$random)

boxplot(data_ts ~ cycle(data_ts))
```

-\> on distingue des saisonnalités =\> faire régression ca n'a pas de sens =\> modèle de Buys Ballot

-\> bonne repartition du bruit -\> quelques outliers

```{r}
checkresiduals(remainder(decomposed_data))
```

On a tendances + saisonnalité

# Modèles espace-état

-   meanf : Average Method : prend la valeur moyenne de toute les observations pour toutes les prédictions,
-   naive : Naive Method : prend la dernière observation pour toutes les prédictions,
-   drift : Drift Method : prend la première et la dernière observations et trace une lignes entre les deux, on utilise la courbe pour les prédictions,
-   snaive : Seasonal Naive Forecast : Prend la dernière valeur de la saison précédente comme prédiction (ex : sept 2018 = sep 2019 + erreur)

```{r}
library(forecast)
mean <- meanf(data_ts_train, h=8)
naivem <- naive(data_ts_train, h=8)
driftm <- rwf(data_ts_train, h=8, drif=T)
snaivem <- snaive(data_ts_train, h=8)
```

```{r}
plot(mean, plot.conf = F, main="")
lines(naivem$mean, col=2, lty=1)
lines(driftm$mean, col=5, lty=1)
lines(snaivem$mean, col = 4, lty=1)
legend("topleft", lty=1, col=c(1,2,3,4), legend=c("Mean Method", "Naive Method", "Drif Method", "Seasonal Naive"))


#comparaison :
plot(snaivem, plot.conf = F, main="")
lines(data_ts_test, col = 6, lty=1, lwd=3)

plot(driftm, plot.conf = F, main="")
lines(data_ts_test, col = 6, lty=1, lwd=3)

```

On regarde : MAE : Mean Absolute Error : RMSE : Root Mean Squarred Error

:   MASE : Mean Absolute Scaled Error : MAPE : Mean Absolute Percentage Error :

res = pred - val MAE = sum(abs(res))/length(val) RSS = sum(res\^2) MSE = RSS/length(val) RMSE = sqrt(MSE)

La plus populaire est la MAPE

MAPE(y_pred, y_true)

\$MAPE = (1/n) \* Σ(\|actual -- forecast\| / \|actu0al\|) \* 10

"a MAPE value of 6% means that the average difference between the forecasted value and the actual value is 6%"

```{r}
print(summary(mean))
checkresiduals(mean)
accuracy(mean, data_ts_test)

```

```{r}
print(summary(naivem))
checkresiduals(naivem)
accuracy(naivem, data_ts_test)

```

```{r}
print(summary(driftm))
checkresiduals(driftm)
accuracy(driftm, data_ts_test)

```

```{r}
print(summary(snaivem))
checkresiduals(snaivem)
accuracy(snaivem, data_ts_test)

```

# Etude du Modèle de Buys-Ballot

## Modèle

<https://mpra.ub.uni-muenchen.de/77718/1/MPRA_paper_77718.pdf> page 175

L'approche de BUYS-BALLOT consiste à introduire des variables indicatrices correspondant à chaque saison définit par le cycle d'observation. Pour les données trimestrielles, on intègre 4 variables indicatrices. Et pour les données mensuelles, on intègre 12 variables indicatrices.

Le modèle doit alors être estimé (sans constante) avec ces variables indicatrices.

## Prédiction des valeurs de 2019

Préparation des données.

```{r}
Annees=as.numeric(time(data_ts_train))
ts_DataFrame =data.frame(trafic=data_ts_train,X=as.numeric(Annees))
```

Création du modèle

```{r}
Regression <- lm(trafic~X,data = ts_DataFrame)
```

$Xt = Zt + St + \mu t$

La tendance Prédiction sur les données futurs.

```{r}
tendance=predict(Regression)

#les 8 prochains mois
AnneeMoisNumericFutur=seq(max(Annees)+1/12,length=8,by=1/12)  

tendance2=predict(Regression, newdata=data.frame(X=AnneeMoisNumericFutur)) 
```

```{r}
ts_DataFrame$trafic_residual <- residuals(Regression)
```

Définissons le mois

```{r}
ts_DataFrame$mois <- round(ts_DataFrame$X - trunc(ts_DataFrame$X),digit=4)
```

Création du 2nd modèle avec les mois

```{r}
Regression2 =lm(trafic_residual~0+as.factor(mois),data=ts_DataFrame)
```

Prédiction de la saisonnalité

```{r}
prediction2 =predict(Regression2)
```

Prédiction sur les mois

```{r}
MoisNumeric= round(AnneeMoisNumericFutur - trunc(AnneeMoisNumericFutur
                     ),4)
Prediction3 =predict( Regression2, newdata= data.frame(mois=MoisNumeric))

```

Calculons une région de confiance avec l'erreur d'ajustement

```{r}
ResidusRegression2=residuals(Regression2)
hist(ResidusRegression2)
1.96*sqrt(var(ResidusRegression2))
```

## Auto corrélation de la série temporelle

L'autocorrélation de notre série temporelle correspond à la corrélation entre une mesure du trafic $t$ et les mesures précédentes $t - k$ ou les mesures suivantes $t + k$.

L'auto covariance d'une variable $Xt$ de moyenne $\mu$ et d'écart type $\sigma$ à un décalage $k$ est donné par la formule

$\gamma_k= E((X_t-\mu)(X_{t+k}-\mu))$

On en déduit l'auto-corrélation correspondante :

$\rho_k=\frac{\gamma_k}{\sigma^2}$

Affichons les auto-corrélations de la séries grâce à un corrélogramme

```{r}
ACF_Sur_Valeurs_Predites <- acf(prediction2)
```

Il est normal que la série soit autocorrélé totalement à elle avec un décalage nulle.

On observe une corrélation forte (0.87) avec un décalage (lag) de 12, cela correspond bien à une saisonnalité annuelle.

```{r}
print(data.frame(ACF_Sur_Valeurs_Predites$lag,ACF_Sur_Valeurs_Predites$acf)[1:13,])
```

Recalculons la valeur d'auto-corrélation obtenu en appliquant la formule.

Observons l'application de la formule, en choisissant un décalage de 12

```{r}
#Constantes
Nombre_Observations=96
decalage=12

#Estimations
moyenneMu=mean(prediction2)
sdSigma=sd(prediction2)


Serie1=prediction2[(decalage+1): 96   ]
Serie2=prediction2[   1 :(96-decalage)]

GammaDecalage12=mean((Serie1-moyenneMu)*(Serie2-moyenneMu))*((Nombre_Observations-decalage)/(Nombre_Observations))

RhoDecalage12=GammaDecalage12/(sdSigma^2)
RhoDecalage12
```

Le résultat obtenu est correct. L'auto corrélation avec un décalage de 12 est donc très forte.

De plus cette auto corrélation étant positive, cela indique une tendance croissante.

la deuxième plus forte corrélation est obsersé avec un décalage de 5, observons cela graphiquement

```{r}
plot  ( 1:length(prediction2),   prediction2,type="l")
points((1:length(prediction2))-5,prediction2,type="l",col="red")
```

Cette corrélation est peu pertinente.

```{r}
print(data.frame(ACF_Sur_Valeurs_Predites$lag,ACF_Sur_Valeurs_Predites$acf)[1:13,])
```

Après avoir étudier les auto-corrélations sur l'ensemble du modèle, Observons les auto-corrélations sur les résidus du modèle de Buys-Ballot.

-   Texte pour dire que les accidents ne doivent pas être corrélés \*

```{r}
plot(acf(ResidusRegression2))
```

Pour notre modèle, il n'y a aucune auto-corrélation significative. (symbolisé par la ligne bleu)

## Comparaison des prédictions et des valeurs réelles

Affichage de la tendance

```{r warning=FALSE}
Buys_ballot_plot_tendance <- plot(data_ts,
                         main = "Application du modèle de Buys_Ballot",
                         xlab = "Années",
                         ylab = "Nombre de Voyageurs") 

#droite de tendance
lines(Annees,tendance,col="blue",lwd=2)  

#prédiction de la tendance futur
lines(AnneeMoisNumericFutur,tendance2,col="red")


```

Affichage du modèle de Buys Ballot

```{r}

Buys_ballot_plot <- plot(data_ts,
                         main = "Application du modèle de Buys_Ballot",
                         xlab = "Années",
                         ylab = "Nombre de Voyageurs") 



#prédiction du modèle de Buys ballot
lines(Annees,tendance+prediction2,col="blue",lwd=2)

#Interval de confiance
 polygon(c(AnneeMoisNumericFutur,rev(AnneeMoisNumericFutur)),
 c(tendance2+Prediction3-1.96*sqrt(var(ResidusRegression2)),
 rev(tendance2+Prediction3+1.96*sqrt(var(ResidusRegression2)))),
 col="cadetblue1",border=NA)
 
 #Prediction des valeurs
 lines(AnneeMoisNumericFutur,tendance2+Prediction3,col="blue",lwd=2)
 
 
 lines(data_ts_test,col="black",lwd=3)
```

Affichage de la prédiction sur les 8 mois de 2020

```{r}

Buys_ballot_plot <- plot(data_ts_test,
                         main = "Application du modèle de Buys_Ballot",
                         xlab = "Années",
                         ylab = "Nombre de Voyageurs") 



#prédiction du modèle de Buys ballot
lines(Annees,tendance+prediction2,col="blue",lwd=2)

#Interval de confiance
 polygon(c(AnneeMoisNumericFutur,rev(AnneeMoisNumericFutur)),
 c(tendance2+Prediction3-1.96*sqrt(var(ResidusRegression2)),
 rev(tendance2+Prediction3+1.96*sqrt(var(ResidusRegression2)))),
 col="cadetblue1",border=NA)
 
 #Prediction des valeurs
 lines(AnneeMoisNumericFutur,tendance2+Prediction3,col="blue",lwd=2)
 
 
 lines(data_ts_test,col="black",lwd=3)
```

Préparation DataFrame pour affichage ggplot

```{r}
DataAffichageGGplot = as.data.frame(data_ts)
DataAffichageGGplot$Annees = c(Annees, AnneeMoisNumericFutur)
DataAffichageGGplot$AnneesRound = round(DataAffichageGGplot$Annees)
DataAffichageGGplot$PredictionTendanceBuysBalot = c(tendance ,tendance2)
DataAffichageGGplot$BuysBalotModele = c(tendance+prediction2,tendance2+Prediction3 )


```

Reproduisons les graphiques avec ggplot2 pour un résultat plus professsionnel.

```{r warning=FALSE}
plotBuysBallot <- Affichage_Prediction(DataAffichageGGplot, DataAffichageGGplot$BuysBalotModele)
plotBuysBallot
```

Sauvegarde de l'image pour utilisation ultérieur dans l'application web.
```{r}
library(tidyverse)
#Utilisation de Cairo pour appliquer de l'anti-Aliasing sur le plot
library('Cairo')

ggsave(plotBuysBallot, path= "Shiny/www",  filename = 'BuysBallotPlotPrediction.png', dpi = 1500, type = 'cairo',
       width = 8, height = 5, units = 'in')

#Save aussi du SeasonPlot
ggsave(SeasonPlot, path= "Shiny/www",  filename = 'SeasonPlot.png', dpi = 1500, type = 'cairo',
       width = 8, height = 5, units = 'in')

```






Nous avons réussi à ajuster une droite de régression. on remarque que la prédiction semble bien correspondre à la réalité si on fait abstraction du dernier mois où le nombre de voyageurs a bien plus chuté que la prédiction du modèle de Buys-Balot.

Comparons avec un ajustement local réalisé par lissage moyennes mobiles.

## Comparaison avec les valeurs observées

# Lissage moyenne mobile

## Définition

Une moyenne mobile est un filtre linéaire. Il permet de transformer une série chronologique avec comme but d'annuler une composante (tendance ou saison) pour en laisser les autres invariantes tout en réduisant le bruit. 

Une moyenne mobile en t est définit comme une combinaison linéaire finie des valeurs de la série correspondant à des dates entourant t, c'est donc un lissage de la série. 

## Choix Moyenne mobiles

## Conservation & Annulation

```{r}
library(forecast)
ma_model <- ma(data_ts_train, order=12, centre=TRUE)
ma_model
plot(data_ts_train)
lines(ma_model, col="blue", lwd=3)

ma_forecast <- forecast(ma_model, h=14)
ma_forecast
plot(ma_forecast)

accuracy(ma_forecast, data_ts_test)

```


```{r}

```

# Lissage exponentielle

## Lissage simple

```{r}
fcst_se <- ses(data_ts_train, h = 8)
print(summary(fcst_se))
checkresiduals(fcst_se)
```

```{r}
plot(fcst_se)
lines(data_ts_test, col="red")


df_se = as.data.frame(fcst_se)
predict_value_se <- df_se$`Point Forecast`
MAPE(predict_value_se, data_ts_test)*100
```

## Optimisation du modèle

Fit Exponential Smoothing model -\> trouve le meilleur lissage expo

```{r}
fit_ets <- ets(data_ts_train) 
print(summary(fit_ets))
checkresiduals(fit_ets)


```

```{r}
fcst_ets <- forecast(fit_ets, h=8)
plot(fcst_ets)
lines(data_ts_test, col="red")




df_ets = as.data.frame(fcst_ets)
predict_value_ets = df_ets$`Point Forecast`
MAPE(predict_value_ets, data_ts_test)*100

```

Affichage GGplot

```{r}
DataAffichageGGplot$ModeleLissageExponentielle <- c(fcst_ets$fitted ,predict_value_ets )

Affichage_Prediction(DataAffichageGGplot, DataAffichageGGplot$ModeleLissageExponentielle)

```




## Modèle ARIMA

A FAIRE

## Modèle ARIMA / SAMIRA Automatique

ARIMA : AutoRegressive Integrated Moving Average

Le modèle ARIMA est une combinaison du modèle ARMA combiné à une différentiation (le Integrated)

Différentiation = rétirer les tendances -\> tendance linéaire : une différenciation -\> tendance quadradique : deux différenciations

Le modèle SARIMA est une combinaison du modèle ARIMA qui prend en compte la composante saisonniaire.

auto.arima prend en compte les saisonnalités, comme on peut le voir dans le modèle selectionné : (0,1,1)(0,1,1)[12]

```{r}
# retourne les meilleurs paramètres 
# d=1 enleve la tendance
# D=1 enleve la saisonnalité 
# => avoir des données stationnaires
# trace : voir les résultats
fit_arima <- auto.arima(data_ts_train, d=1, D=1, stepwise = FALSE, approximation = FALSE, trace=TRUE)
print(summary(fit_arima))
checkresiduals(fit_arima)
```

```{r}
fcst_arima <- forecast(fit_arima, h=8)
plot(fcst_arima)
lines(data_ts_test, col='red')


df_arima = as.data.frame(fcst_arima)
predict_value_arima = df_arima$`Point Forecast`
MAPE(predict_value_arima, data_ts_test)*100
```

Affichage GGplot

```{r}
DataAffichageGGplot$ModeleArima <-  c(fit_arima$fitted ,predict_value_arima )
Affichage_Prediction(DataAffichageGGplot, DataAffichageGGplot$ModeleArima)
```

## PROPHET

Prophet est un outil de prévision de série chronologique open-source mis en production par Facebook.

L'idée est décomposer la série temporelle sous la forme : 

y(t) = g(t) + s(t) + h(t) + e(t)

avec respectivement :

- g(t) : la tendance (linéaire ou logistique)
- s(s) : une ou plusieurs composantes saisonnières (annuelle, hebdomadaire ou            quotidienne)
- h(t) : l’effet des vacances ou de jours spécifiques qui pourront être paramétrés
- e(t) : l’erreur, bruit aléatoire qui mesure l’écart entre le modèle et les données réelles

Ce modèle est particulièrement utile quand on a de forte saisonnalités et permet de prendre en compte les vacances (et ses effets) par pays. 

Préparation des données:
- format des dates 
- colonne du temps name : ds
- colonne de la mesure quantitative name : y

```{r}
library(prophet)
library(zoo)
data_train$ds <- as.Date( as.yearmon(time(data_ts_train)))
```

On créer notre modèle et on predit sur les 8 mois de 2019.

On affiche les courbes.

On regarde la valeur de la MAPE : 3.2.

```{r}
model_prophet <- prophet(data_train)
forecast_prophet <- make_future_dataframe(model_prophet, periods = 8, freq = 'month')
AAPLfc <- predict(model_prophet, forecast_prophet)
tail(AAPLfc[c("ds", "yhat", "yhat_lower", "yhat")])


dyplot.prophet(model_prophet, AAPLfc)



data_pp <- subset(AAPLfc, select=c("yhat"))
data_pp_ts <- ts(data_pp, start=2011, frequency=12)
data_pp_ts_w <- window(data_pp_ts, start= c(2019,1), end = c(2019,8))
MAPE(data_pp_ts_w, data_ts_test) #3.2
# 
# 
# plot(data_ts)
# lines(data_pp_ts_w, col="red")
 


```

Affichage GGplot

```{r}
DataAffichageGGplot$ProphetModele <- AAPLfc$yhat
Affichage_Prediction(DataAffichageGGplot, DataAffichageGGplot$ProphetModele)
```

## LSTM

```{r}

scale_factors <- c(mean(data$y), sd(data$y))
scaled_train <- data %>%
    dplyr::select(y) %>%
    dplyr::mutate(y = (y - scale_factors[1]) / scale_factors[2])
scaled_train



prediction <- 12
lag <- prediction
```

On veut prendre l'année précedente pour apprendre \> lag de 12, en réalité ca fait 12 - 1 pour avoir à chaque prédiction basée sur 12 valeurs

puis en transforme en array 3D car le modèle LSTM prendre un tensor de format 3D [samples, timesteps, features] samples : nbr d'observation par batchs timesteps : lag features : nbr de valeur predites

```{r}
scaled_train <- as.matrix(scaled_train)
 
# we lag the data 11 times and arrange that into columns
x_train_data <- t(sapply(
    1:(length(scaled_train) - lag - prediction + 1),
    function(x) scaled_train[x:(x + lag - 1), 1]
  ))
 
# now we transform it into 3D form
x_train_arr <- array(
    data = as.numeric(unlist(x_train_data)),
    dim = c(
        nrow(x_train_data),
        lag,
        1
    )
)

#(x_train_data)
#length(x_train_arr)
#head(x_train_arr)
```

```{r}
y_train_data <- t(sapply(
    (1 + lag):(length(scaled_train) - prediction + 1),
    function(x) scaled_train[x:(x + prediction - 1)]
))

y_train_arr <- array(
    data = as.numeric(unlist(y_train_data)),
    dim = c(
        nrow(y_train_data),
        prediction,
        1
    )
)

#head(y_train_data)
#head(y_train_arr)
```

```{r}
x_test <- data$y[(nrow(scaled_train) - prediction + 1):nrow(scaled_train)]

x_test_scaled <- (x_test - scale_factors[1]) / scale_factors[2]

x_pred_arr <- array(
    data = x_test_scaled,
    dim = c(
        1,
        lag,
        1
    )
)

```

```{r}
lstm_model <- keras_model_sequential()

lstm_model %>%
  layer_lstm(units = 50, # size of the layer
       batch_input_shape = c(1, 12, 1), # batch size, timesteps, features
       return_sequences = TRUE,
       stateful = TRUE) %>%
  # fraction of the units to drop for the linear transformation of the inputs
  layer_dropout(rate = 0.5) %>%
  layer_lstm(units = 50,
        return_sequences = TRUE,
        stateful = TRUE) %>%
  layer_dropout(rate = 0.5) %>%
  time_distributed(keras::layer_dense(units = 1))

lstm_model %>%
    compile(loss = 'mae', optimizer = 'adam', metrics = 'accuracy')

summary(lstm_model)


```

```{r}
lstm_model %>% fit(
    x = x_train_arr,
    y = y_train_arr,
    batch_size = 1,
    epochs = 20,
    verbose = 0,
    shuffle = FALSE
)
```

```{r}
lstm_forecast <- lstm_model %>%
    predict(x_pred_arr, batch_size = 1) %>%
    .[, , 1]
 
# rescale en format basique
lstm_forecast <- lstm_forecast * scale_factors[2] + scale_factors[1]
lstm_forecast
```

X résultats / prédictions par input donc \> transforme pour une seule prédiciton

```{r}
fitted <- predict(lstm_model, x_train_arr, batch_size = 1) %>%
     .[, , 1]

if (dim(fitted)[2] > 1) {
  
    fit <- c(fitted[, 1], fitted[dim(fitted)[1], 2:dim(fitted)[2]])
} else {
    fit <- fitted[, 1]
}

# rescale final de nos données
fitted <- fit * scale_factors[2] + scale_factors[1]
fitted
fitted <- c(rep(NA, lag), fitted)
fitted
length(fitted)

```

```{r}
lstm_forecast <- ts(lstm_forecast,
    start = c(2019, 1),
    end = c(2019, 12),
    frequency = 12
)

lstm_forecast_display <- window(lstm_forecast, start= c(2019,1), end = c(2019,8))

input_ts <- ts(data$y, 
    start = c(2011, 1), 
    end = c(2018, 12), 
    frequency = 12)


lstm_forecast_display
data_ts_test

plot(input_ts, xlim=c(2011,2020))
#lines(data_ts_test)
lines(lstm_forecast_display, col=3)



```

Affichage GGplot

```{r}
DataAffichageGGplot$LSTM_Modele <- fitted
Affichage_Prediction(DataAffichageGGplot, DataAffichageGGplot$LSTM_Modele)
```

# Comparaison Modèle

## Choix des indicateurs

Nous devons pouvoir comparer nos modèles entre eux, nous souhaitons pouvoir observer leurs performances globale, ainsi que spécifiquement leurs performances sur le jeu d'entraînement et le jeu de test (les 8 mois de 2019 à prédire).

Nous utiliserons une mesure largement utilisé lors de nos précédents travaux : le $R^2 \in [0 \; ; 1]$ , cette mesure indique la proportion de la variance expliquée par le modèle.

-   0 % le modèle n'explique par la variable Y

-   100 % le modèle explique la variabilité de Y lié à la liaison linéaire des variables explicatives entièrement

Rappelons son explication mathématiques , soit SCE la somme des distances au carré entre chaque valeur prédite par le modèle ${\widehat y_i}$ et la moyenne des réponses $\overline{y}$

$\text{SCE} = \sum_{i=1}^{N}(\hat{y_i} – \overline{y})^2$

Nous obtenons alors la part de dispersion expliquée par le modèle.

Puis, nous calculons la dispersion totale des données nommé SCT

$\text{SCT} = \sum_{i=1}^{N}(y_{i } – \overline{y})^2$

*Avec* $y_i$ *une valeur prise par une variable expliquée*

Nous obtenons alors le R² par la combinaisons des calculs précédents

$R^2 = \frac{SCE}{SCT}$

Pour compléter cette mesure, nous utiliserons donc l'erreur absolue moyenne en pourcentage (MAPE en anglais) Il s'agit de la moyenne des écarts en valeur absolue par rapport aux valeurs observées.

C'est donc un pourcentage et par conséquent un indicateur pratique de comparaison.

**Exemple de mise en production**

Imaginons que l'on utilise nos modèles pour prédire le nombre de voyageurs, si l'on prévoit trop de passagers alors les moyens mis en place pour les accueillir sont partiellement utilisés, il en résulte un coût de 5 euros par passagers.

Si l'on a prédit moins de passagers que la réalité, notre compagnie doit commander en livraison urgente, il en résulte un coût de 10 euros par passagers.

Observons cette mise en production sur nos modèles.

## Calculs des performances

Dans les concerts, chaque individu chante comme une casserole, pourtant la foule chante systématiquement juste, suivant cet intuition réalisons une prédiction qui est une moyenne des différents modèles réalisés.

```{r}
DataAffichageGGplot$MoyenneDesModele <- rowMeans(DataAffichageGGplot[,5:9])
```

Performances Modèles

```{r}
noms_modeles <- c("Buys Ballot ","Lissage exponentielle ","Arima","Prophet","LSTM","Moyenne Des Modèles")

for (x in seq_along(noms_modeles)){
  print("----------------------------")
  print(noms_modeles[x])
  
  predictionglobale <- DataAffichageGGplot[13:104,4+x]
  predictionEntrainement <- DataAffichageGGplot[13:96,4+x]
  predictionTest <- DataAffichageGGplot[97:104,4+x]
    
  
  cat("MAPE globale : ",MAPE(DataAffichageGGplot$trafic[13:104], predictionglobale),"\n")
cat("R carré globale : ",Rcarre(DataAffichageGGplot$trafic[13:104], predictionglobale),"\n")

cat("MAPE Entrainement : ",MAPE(DataAffichageGGplot$trafic[13:96], predictionEntrainement),"\n")
cat("R carré Entrainement : ",Rcarre(DataAffichageGGplot$trafic[13:96], predictionEntrainement),"\n")

cat("MAPE Test : ",MAPE(DataAffichageGGplot$trafic[97:104], predictionTest),"\n")
cat("R carré Test : ",Rcarre(DataAffichageGGplot$trafic[97:104], predictionTest),"\n")

MiseEnProductionDuModele <-  CoutDesErreurs(DataAffichageGGplot$trafic[97:104], predictionTest)
cat("Nombre de Passagers prévus en plus : ",MiseEnProductionDuModele[1],"\nNombre de Passagers prévus en moins : ",MiseEnProductionDuModele[2],"\nCout des erreurs en Euros : ",MiseEnProductionDuModele[3] )


cat("\nDifférence en nbre de voyageurs sur le dernier mois : ",predictionglobale[92] - DataAffichageGGplot$trafic[104],"\n")
  
}
```

Sauvegardons le modèle de Buys Ballot pour une utilisation ultérieur dans une application Web
```{r}
saveRDS(Regression, file = "./Shiny/RegressionAnnees.rda")
saveRDS(Regression2, file = "./Shiny/RegressionMois.rda")
```



## Conclusion

lorem ipsum
