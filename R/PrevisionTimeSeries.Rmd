---
title: |
  
author: 
- Clovis Deletre
- Charles Vitry
date:
output:
  html_notebook:
    theme: cerulean
    number_sections: no
    toc: yes
    toc_float: true
editor_options: 
  markdown: 
    wrap: 72
---

```{=html}
<style type="text/css">

body{ /* Normal  */
      font-size: 20px;
  }
td {  /* Table  */
  font-size: 8px;
}
h1.title {
  font-size: 55px;
  color: DarkBlue;
}
h1 { /* Header 1 */
  font-size: 38px;
  color: DarkBlue;
}
h2 { /* Header 2 */
    font-size: 28px;
  color: DarkBlue;
}
h3 { /* Header 3 */
  font-size: 35px;
  font-family: "Times New Roman", Times, serif;
  color: DarkBlue;
}
code.r{ /* Code block */
    font-size: 12px;
}
pre { /* Code block - determines code spacing between lines */
    font-size: 14px;
}
</style>
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

source("Fonctions.R", local = knitr::knit_global())

#install for export in pdf file
#tinytex::install_tinytex()
```

<br> </br>

```{r include=FALSE}
if(!require(forecast)) install.packages("tm", repos = "http://cran.us.r-project.org")
require(forecast)

if(!require(fpp2)) install.packages("tm", repos = "http://cran.us.r-project.org")
require(fpp2)

if(!require(MLmetrics)) install.packages("tm", repos = "http://cran.us.r-project.org")
require(MLmetrics)

if(!require(ggplot2)) install.packages("tm", repos = "http://cran.us.r-project.org")
require(ggplot2)

if(!require(fpp2)) install.packages("tm", repos = "http://cran.us.r-project.org")
require(fpp2)

if(!require(TSstudio)) install.packages("tm", repos = "http://cran.us.r-project.org")
require(TSstudio)
```

# Introduction

Nous souhaitons réalisé l'**étude d'une série temporelle** et faire des
prévisions sur celle-ci.

Cette série temporelle est le trafic mensuel d'une Compagnie aérienne de
janvier 2011 à août 2019.

Nos prévisions portent sur les 8 mois de l'année 2019

# Représentation graphique de la série.

## Import des données

Import de la base, on sélectionne la colonne des valeurs

```{r}
library(readr)
data <- read_delim("Trafic-voyageurs.csv", 
    delim = ";", locale = locale(encoding = "ISO-8859-1"))
```

```{r}
summary(data)
```

```{r}
data_value <- data[,2]
```

## Affichage

Création de la série chronologique :

```{r}
library(TSstudio)
data_ts <- ts(data_value, start=2011, frequency=12)
plot_1_TimeSeries(data_ts)
```

## Séparation jeu de données

```{r}
#revoir l affichage car ca prend pas en compte tt 2019
data_ts_train <- window(data_ts, start = c(2011, 1), end = c(2018,12))
data_ts_test <- window(data_ts, start= c(2019,1), end = c(2019,8))

plot(data_ts, xlim=c(2011,2020))
lines(data_ts_test, col=3)
legend("topleft", lty = 1, col=c(1,3), legend=c("Série chronologique Train", "Série chronologique Test"))
```

-> strong trend -> patern qui se repete, saisonnalité ?

## Représentation de la saisonnalité

Analyse de la saisonnalité en superposant chaque année (par mois):

-> en supprimant la tendance on voit bien la saisonnalité =>
saisonnalité régulière

```{r}
ggseasonplot(data_ts)
data_ts_without_trend = diff(data_ts)
ggseasonplot(data_ts_without_trend)
```

## Représentation des décompositions possibles

DECOMPOSITION : additive / Multiplicative Ts = Trend + Seasonal + Random
/ Ts = Trend \* Seasonal \* Random

```{r}
decomposed_data <- decompose(data_ts_train, type="additive")
plot(decomposed_data$trend)
plot(decomposed_data$seasonal)
plot(decomposed_data$random)

boxplot(data_ts ~ cycle(data_ts))
```

-> on distingue des saisonnalités => faire régression ca n'a pas de sens
=> modèle de Buys Ballot

-> bonne repartition du bruit -> quelques outliers

```{r}
checkresiduals(remainder(decomposed_data))
```

On a tendances + saisonnalité


# Modèles espace-état

-   meanf : Average Method : prend la valeur moyenne de toute les
    observations pour toutes les prédictions,
-   naive : Naive Method : prend la dernière observation pour toutes les
    prédictions,
-   drift : Drift Method : prend la première et la dernière observations
    et trace une lignes entre les deux, on utilise la courbe pour les
    prédictions,
-   snaive : Seasonal Naive Forecast : Prend la dernière valeur de la
    saison précédente comme prédiction (ex : sept 2018 = sep 2019 +
    erreur)

```{r}
library(forecast)
mean <- meanf(data_ts_train, h=8)
naivem <- naive(data_ts_train, h=8)
driftm <- rwf(data_ts_train, h=8, drif=T)
snaivem <- snaive(data_ts_train, h=8)
```

```{r}
plot(mean, plot.conf = F, main="")
lines(naivem$mean, col=2, lty=1)
lines(driftm$mean, col=5, lty=1)
lines(snaivem$mean, col = 4, lty=1)
legend("topleft", lty=1, col=c(1,2,3,4), legend=c("Mean Method", "Naive Method", "Drif Method", "Seasonal Naive"))


#comparaison :
plot(snaivem, plot.conf = F, main="")
lines(data_ts_test, col = 6, lty=1, lwd=3)

plot(driftm, plot.conf = F, main="")
lines(data_ts_test, col = 6, lty=1, lwd=3)

```

On regarde : MAE : Mean Absolute Error : RMSE : Root Mean Squarred Error

:   MASE : Mean Absolute Scaled Error : MAPE : Mean Absolute Percentage
    Error :

res = pred - val MAE = sum(abs(res))/length(val) RSS = sum(res\^2) MSE =
RSS/length(val) RMSE = sqrt(MSE)

La plus populaire est la MAPE

MAPE(y_pred, y_true)

$MAPE = (1/n) \* Σ(\|actual -- forecast\| / \|actu0al\|) \* 10 

"a MAPE value of 6% means that the average difference between the forecasted
value and the actual value is 6%"

```{r}
print(summary(mean))
checkresiduals(mean)
accuracy(mean, data_ts_test)

```

```{r}
print(summary(naivem))
checkresiduals(naivem)
accuracy(naivem, data_ts_test)

```

```{r}
print(summary(driftm))
checkresiduals(driftm)
accuracy(driftm, data_ts_test)

```

```{r}
print(summary(snaivem))
checkresiduals(snaivem)
accuracy(snaivem, data_ts_test)

```





# Etude du Modèle de Buys-Ballot

## Modèle

<https://mpra.ub.uni-muenchen.de/77718/1/MPRA_paper_77718.pdf> page 175

L'approche de BUYS-BALLOT consiste à introduire des variables
indicatrices correspondant à chaque saison définit par le cycle
d'observation. Pour les données trimestrielles, on intègre 4 variables
indicatrices. Et pour les données mensuelles, on intègre 12 variables
indicatrices.

Le modèle doit alors être estimé (sans constante) avec ces variables
indicatrices.

## Prédiction des valeurs de 2019

Préparation des données.

```{r}
Annees=as.numeric(time(data_ts_train))
ts_DataFrame =data.frame(trafic=data_ts_train,X=as.numeric(Annees))
```

Création du modèle

```{r}
Regression <- lm(trafic~X,data = ts_DataFrame)
```

$Xt = Zt + St + \mu t$

La tendance Prédiction sur les données futurs.

```{r}
tendance=predict(Regression)

AnneeMoisNumericFutur=seq(max(Annees)+1/12,length=8,by=1/12)  #les 10 prochains mois

tendance2=predict(Regression, newdata=data.frame(X=AnneeMoisNumericFutur)) 
```

```{r}
ts_DataFrame$trafic_residual <- residuals(Regression)
```

Définissons le mois

```{r}
ts_DataFrame$mois <- round(ts_DataFrame$X - trunc(ts_DataFrame$X),digit=4)
```

Création du 2nd modèle avec les mois

```{r}
Regression2 =lm(trafic_residual~0+as.factor(mois),data=ts_DataFrame)
```

Prédiction de la saisonnalité

```{r}
prediction2 =predict(Regression2)
```

Prédiction sur les mois

```{r}
MoisNumeric= round(AnneeMoisNumericFutur - trunc(AnneeMoisNumericFutur
                     ),4)
Prediction3 =predict( Regression2, newdata= data.frame(mois=MoisNumeric))

```

Calculons une région de confiance avec l'erreur d'ajustement

```{r}
ResidusRegression2=residuals(Regression2)
hist(ResidusRegression2)
1.96*sqrt(var(ResidusRegression2))
```

## Auto corrélation de la série temporelle

L'autocorrélation de notre série temporelle correspond à la corrélation
entre une mesure du trafic $t$ et les mesures précédentes $t - k$ ou les
mesures suivantes $t + k$.

L'auto covariance d'une variable $Xt$ de moyenne $\mu$ et d'écart type
$\sigma$ à un décalage $k$ est donné par la formule

$\gamma_k= E((X_t-\mu)(X_{t+k}-\mu))$

On en déduit l'autocorrélation correspondante :

$\rho_k=\frac{\gamma_k}{\sigma^2}$

Affichons les autocorrélations de la séries grâce à un corrélogramme

```{r}
ACF_Sur_Valeurs_Predites <- acf(prediction2)
```

Il est normal que la série soit autocorrélé totalement à elle avec un
décalage nulle.

On observe une corrélation forte (0.87) avec un décalage (lag) de 12,
cela correspond bien à une saisonnalité annuelle.

```{r}
print(data.frame(ACF_Sur_Valeurs_Predites$lag,ACF_Sur_Valeurs_Predites$acf)[1:13,])
```

Recalculons la valeur d'auto-corrélation obtenu en appliquant la formule.

Observons l'application de la formule, en choisissant un
décalage de 12

```{r}
#Constantes
Nombre_Observations=96
decalage=12

#Estimations
moyenneMu=mean(prediction2)
sdSigma=sd(prediction2)


Serie1=prediction2[(decalage+1): 96   ]
Serie2=prediction2[   1 :(96-decalage)]

GammaDecalage12=mean((Serie1-moyenneMu)*(Serie2-moyenneMu))*((Nombre_Observations-decalage)/(Nombre_Observations))

RhoDecalage12=GammaDecalage12/(sdSigma^2)
RhoDecalage12
```

Le résultat obtenu est correct. La corrélation avec un décalage de 12 est donc très forte.



la deuxième plus forte corrélation est obsersé avec un décalage de 5,
observons cela graphiquement

```{r}
plot  ( 1:length(prediction2),   prediction2,type="l")
points((1:length(prediction2))-5,prediction2,type="l",col="red")
```

Cette corrélation est peu pertinente.



```{r}
print(data.frame(ACF_Sur_Valeurs_Predites$lag,ACF_Sur_Valeurs_Predites$acf)[1:13,])
```

Après avoir étudier les auto-corrélations sur l'ensemble du modèle,
Observons les auto-corrélations sur les résidus du modèle de Buys-Ballot.

* Texte pour dire que les accidents ne doivent pas être corrélés *


```{r}
plot(acf(ResidusRegression2))
```
Pour notre modèle, il n'y a aucune auto-corrélation significative. (symbolisé par la ligne bleu)



## Comparaison des prédictions et des valeurs réelles

Affichage de la tendance

```{r warning=FALSE}
Buys_ballot_plot_tendance <- plot(data_ts,
                         main = "Application du modèle de Buys_Ballot",
                         xlab = "Années",
                         ylab = "Nombre de Voyageurs") 

#droite de tendance
lines(Annees,tendance,col="blue",lwd=2)  

#prédiction de la tendance futur
lines(AnneeMoisNumericFutur,tendance2,col="red")


```

Affichage du modèle de Buys Ballot

```{r}

Buys_ballot_plot <- plot(data_ts,
                         main = "Application du modèle de Buys_Ballot",
                         xlab = "Années",
                         ylab = "Nombre de Voyageurs") 



#prédiction du modèle de Buys ballot
lines(Annees,tendance+prediction2,col="blue",lwd=2)

#Interval de confiance
 polygon(c(AnneeMoisNumericFutur,rev(AnneeMoisNumericFutur)),
 c(tendance2+Prediction3-1.96*sqrt(var(ResidusRegression2)),
 rev(tendance2+Prediction3+1.96*sqrt(var(ResidusRegression2)))),
 col="cadetblue1",border=NA)
 
 #Prediction des valeurs
 lines(AnneeMoisNumericFutur,tendance2+Prediction3,col="blue",lwd=2)
 
 
 lines(data_ts_test,col="black",lwd=3)
```

Affichage de la prédiction sur les 8 mois de 2020

```{r}

Buys_ballot_plot <- plot(data_ts_test,
                         main = "Application du modèle de Buys_Ballot",
                         xlab = "Années",
                         ylab = "Nombre de Voyageurs") 



#prédiction du modèle de Buys ballot
lines(Annees,tendance+prediction2,col="blue",lwd=2)

#Interval de confiance
 polygon(c(AnneeMoisNumericFutur,rev(AnneeMoisNumericFutur)),
 c(tendance2+Prediction3-1.96*sqrt(var(ResidusRegression2)),
 rev(tendance2+Prediction3+1.96*sqrt(var(ResidusRegression2)))),
 col="cadetblue1",border=NA)
 
 #Prediction des valeurs
 lines(AnneeMoisNumericFutur,tendance2+Prediction3,col="blue",lwd=2)
 
 
 lines(data_ts_test,col="black",lwd=3)
```
Préparation DataFrame pour affichage ggplot
```{r}
DataAffichageGGplot = as.data.frame(data_ts)
DataAffichageGGplot$Annees = c(Annees, AnneeMoisNumericFutur)
DataAffichageGGplot$AnneesRound = round(DataAffichageGGplot$Annees)
DataAffichageGGplot$PredictionTendance = c(tendance ,tendance2)
DataAffichageGGplot$BuysBalotModele = c(tendance+prediction2,tendance2+Prediction3 )


```



Reproduisons les graphiques avec ggplot2 pour un résultat plus professsionnel.
```{r warning=FALSE}
library(ggplot2)
library(ggthemes)

p <- ggplot(data =DataAffichageGGplot, aes(x = Annees) ) + 

  geom_line(aes(y = trafic ), size = 0.9, alpha = 0.7)+

  #geom_line(aes(y = PredictionTendance), size = 0.6, alpha = 0.85,linetype="twodash" )+
  
  geom_line(aes(y = BuysBalotModele), size = 1.2, alpha = 0.6, color = "blue")+
  labs(title = "Application du modèle de Buys_Ballot",
       x="Années",
         y= "Nombre de Voyageurs")+
theme_fivethirtyeight()+
  theme(axis.title = element_text(), text = element_text(family = "Rubik")) 

#sur l'année 2019
p2 <- ggplot(data =DataAffichageGGplot, aes(x = Annees) ) + 
  geom_line(aes(y = trafic ), size = 1.2, alpha = 0.7)+
  geom_line(aes(y = BuysBalotModele), size = 1.4, alpha = 0.6, color = "blue")+
theme_fivethirtyeight()+
   xlim (2019.0, 2019.583) +
  ylim (435000, 520000) 


#Ajout zoom sur 2019
p + 
  annotation_custom(ggplotGrob(p2), xmin = 2015, xmax = 2020, ymin = 50000, ymax = 280000) +
  geom_rect(aes(xmin = 2015, xmax = 2020, ymin = 50000, ymax = 280000), color='black', linetype='dashed', alpha=0) 



```



Nous avons réussi à ajuster une droite de régression. on remarque que la
prédiction semble bien correspondre à la réalité si on fait abstraction
du dernier mois où le nombre de voyageurs a bien plus chuté que la
prédiction du modèle de Buys-Balot.

Comparons avec un ajustement local réalisé par lissage moyennes mobiles.

## Comparaison avec les valeurs observées


# Lissage moyenne mobile

## Définition

Mettre belle formule en latex ici

## Choix Moyenne mobiles

## Conservation & Annulation




# Lissage exponentielle

## Lissage simple

```{r}
fcst_se <- ses(data_ts_train, h = 8)
print(summary(fcst_se))
checkresiduals(fcst_se)
```

```{r}
plot(fcst_se)
lines(data_ts_test, col="red")


df_se = as.data.frame(fcst_se)
predict_value_se <- df_se$`Point Forecast`
MAPE(predict_value_se, data_ts_test)*100
```

## Optimisation du modèle

Fit Exponential Smoothing model -> trouve le meilleur lissage expo

```{r}
fit_ets <- ets(data_ts_train) 
print(summary(fit_ets))
checkresiduals(fit_ets)


```

```{r}
fcst_ets <- forecast(fit_ets, h=8)
plot(fcst_ets)
lines(data_ts_test, col="red")


df_ets = as.data.frame(fcst_ets)
predict_value_ets = df_ets$`Point Forecast`
MAPE(predict_value_ets, data_ts_test)*100

```

## Modèle Arima Automatique

```{r}
# retourne les meilleurs paramètres 
# d=1 enleve la tendance
# D=1 enleve la saisonnalité 
# => avoir des données stationnaires
# trace : voir les résultats
fit_arima <- auto.arima(data_ts_train, d=1, D=1, stepwise = FALSE, approximation = FALSE, trace=TRUE)
print(summary(fit_arima))
checkresiduals(fit_arima)
```

```{r}
fcst_arima <- forecast(fit_arima, h=8)
plot(fcst_arima)
lines(data_ts_test, col='red')


df_arima = as.data.frame(fcst_arima)
predict_value_arima = df_arima$`Point Forecast`
MAPE(predict_value_arima, data_ts_test)*100
```

```{r}

```

```{r}


```
